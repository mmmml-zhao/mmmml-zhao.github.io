---
layout: main
title: MCP协议使用
date: 2025-06-19 14:09:30 +0800
description: 使用MCP协议调用本地模型的聊天页面
tags: [大模型,MCP,Chat]
---

## 大体流程
1. 下载Ollama，下载并运行deepseek-r1:7b模型。
2. 借助大模型学习如何编写MCP协议服务。  
通过多轮对话生成下方项目结构：
```
mcp-service/
├── mcp/                       # MCP协议核心实现
│   ├── protocol.js            # MCP协议解析/格式化
│   ├── session.js             # 会话管理
│   └── llm_adapter.js         # LLM模型适配器
│
├── public/                    # 静态资源目录
│   └── style.css              # 主样式表
│
├── .gitignore                 # Git忽略文件配置
├── index.html                 # 前端主页面
├── package-lock.json          # 依赖锁定文件
├── package.json               # 项目配置和依赖管理
├── README.md   
├── redis.js                   # Redis单例
└── server.js                  # 主服务器入口
```
3. 在docker里运行 Redis。
4. 运行node服务即可在浏览器打开页面调试。

## MCP到底是什么 （此段内容参考自DeepSeek的回答）

### MCP协议的核心定义与目标
1. 核心问题解决
   - 打破数据孤岛：传统LLM需为每个数据源（如数据库、API、本地文件）定制开发接口，而MCP通过统一协议支持访问本地资源（如SQLite、文件系统）和远程资源（如Slack、GitHub API）。
   - 上下文连续性：支持双向通信，使AI在复杂任务中（如多步工具调用）保持对话状态，避免传统API的无状态限制。
   - 安全可控：通过服务器端管控资源权限，避免敏感数据直接暴露给模型，例如银行系统通过本地部署访问数据库。
  
2. 技术类比
   - 传统API仅提供无状态的服务，无法串联。
   - 与Function Calling区别：Function Calling是模型内部快捷指令（如OpenAI的预定义函数），而MCP是独立服务端程序，支持异步、跨平台和复杂任务编排。

### MCP架构与核心组件
满足MCP协议需实现以下架构组件：

1. MCP主机（Host）   
   - 角色：发起请求的应用程序（如Claude Desktop、IDE）。  
   - 要求：集成MCP客户端模块，管理工具调用流程。

2. MCP客户端（Client）  
   - 角色：与服务器1:1连接的中介。  
   - 要求：  
     * 实现协议层（消息封装/请求关联）。
     * 支持传输层：Stdio（本地进程通信）或HTTP+SSE（远程流式传输）。

3. MCP服务器（Server）
   - 角色：轻量级程序，封装资源供客户端调用。
   - 要求：
     * 暴露标准化接口（如资源列表、工具函数）。
     * 内置安全机制（如权限校验、沙箱隔离）。

4. 资源层（Resources）
   - 本地资源：数据库、文件等，需通过Server安全访问。
   - 远程资源：第三方API，由Server代理调用。

### 满足MCP协议的技术要求
1. 协议规范要求.     
    | 组件       | 必备能力                                                        |
    | ---------- | --------------------------------------------------------------- |
    | 消息格式   | 遵循JSON-RPC 2.0标准，包含四类消息：请求、结果、错误、通知      |
    | 工具定义   | 明确定义工具名称、描述、参数结构（类似OpenAI Function Calling） |
    | 上下文管理 | 支持会话标识符（Session ID）传递，确保多轮调用上下文连贯        |

2. 传输层要求
   - Stdio模式：本地部署时，Client通过标准输入/输出与Server子进程通信。
   - HTTP+SSE模式：远程调用时，使用Server-Sent Events（SSE）实现流式响应。
  
3. 安全要求
   - 权限隔离：Server需控制资源访问粒度（如仅允许读取特定数据库表）
   - 凭证管理：敏感信息（如API Key）通过环境变量注入，避免硬编码

### 与传统前后端架构的本质差异
1. 核心目标差异    
   | 维度     | 传统前后端架构              | MCP协议              |
   | -------- | --------------------------- | -------------------- |
   | 核心目标 | 人类用户的高效信息交互      | LLM与工具的无缝协作  |
   | 交互主体 | 人类 ↔ 应用系统             | AI模型 ↔ 工具生态    |
   | 价值重心 | 业务逻辑实现 & 用户体验优化 | 降低AI使用工具的门槛 |
    
    本质区别：传统架构服务人类认知（需界面转化信息），MCP服务机器认知（需自然语言兼容的接口）
2. 协议设计差异（关键技术特征对比）
   ![协议设计差异](../assets/img/2025-06-19/协议设计差异.png)
   示例：传统API：查询订单物流需每次传递order_id，MCP：模型说"查上笔订单物流"，Server自动关联会话ID对应的历史订单。
3. 安全模型差异    
   | 维度     | 传统前后端架构     | MCP协议                      |
   | -------- | ------------------ | ---------------------------- |
   | 认证对象 | 人类用户身份       | 工具执行权限（与用户解耦）   |
   | 权限控制 | 角色访问控制(RBAC) | 工具级沙箱（如禁止文件删除） |
   | 凭证管理 | Cookie/OAuth令牌   | 环境变量注入+运行时隔离      |



总结：MCP的核心价值与实现路径
MCP通过标准化接口统一了AI与外部系统的交互方式，其核心要求是遵循客户端-服务器架构、实现协议层/传输层规范，并保障安全性。开发者可通过以下步骤快速实践：  

1. 搭建Server：用Python SDK封装工具（如数据库查询）。  
2. 集成Client：在Host应用（如IDE）中配置Server连接。  
3. 调用工具：通过自然语言触发自动化的工具链（如"生成React组件→部署到Vercel"）。  

尽管生态建设仍需时间，MCP已成为解决AI数据集成问题的关键基础设施，推动Agent从"聊天机器人"向"任务执行者"演进。

## 项目相关

### 项目概述
这是一个基于MCP协议的前端聊天应用，允许用户通过Web界面与本地运行的DeepSeek模型进行对话。项目实现了完整的MCP协议栈，包括协议解析、会话管理和模型适配。

### 核心功能
- 基于MCP协议的本地模型调用
- 实时聊天界面
- 会话历史管理（使用Redis存储）
- 支持流式响应

### 技术栈
- 前端：原生HTML/CSS/JavaScript
- 后端：Node.js + Express
- 数据库：Redis（会话存储）
- 模型：DeepSeek R1 7B（通过Ollama运行）

### 代码 
https://github.com/mmmml-zhao/test-deepseek-r1-7b

### 大体页面
![chat page](../assets/img/2025-06-19/会话页面.png)

### 组件关系图
![组件关系图](../assets/img/2025-06-19/组件关系图.png)
